{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_Classifier_Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUzJ9slZCJsU",
        "outputId": "757335b2-f3de-4d1a-95c2-fb5abaaf083f"
      },
      "source": [
        "Messages = []\n",
        "Messages.append(\"Please enter your bank account number here \")\n",
        "Messages.append(\"Winner claim secret prize now\")\n",
        "Messages.append(\"You’ve Won!\")\n",
        "Messages.append(\" How was your day\")\n",
        "Messages.append(\"Amazon Gift card worth Rs 500!!! \")\n",
        "Messages.append(\"Winner claim secret prize now\")\n",
        "Messages.append(\"Hurry !Claim your prize of Rs 50000 now\")\n",
        "Messages.append(\"Good luck with School\")\n",
        "Messages.append(\"Buy our new product to give you guaranteed results\")\n",
        "Messages.append(\"Let's go shopping tomorrow!\")\n",
        "Mes = input(\"Enter message \")\n",
        "Messages.append(Mes)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter message send credit card info \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gEy2qVICn8B"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH9m2ZEuDpoX"
      },
      "source": [
        "def fetch_words(message):\n",
        "    \"\"\"Get the list of words from a message .\n",
        "\n",
        "     \n",
        "    \"\"\"\n",
        "    #We remove punctuations in the message\n",
        "    punctuations='~`!@#$%^&*(),.:\\\";\\'-+=_0123456789?£'\n",
        "    for p in punctuations:\n",
        "        message = message.replace(p,'')\n",
        "    words =  message.lower().split(' ')\n",
        "    return words\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmo04B7fEZFd"
      },
      "source": [
        "def create_dictionary(messages):\n",
        "    \"\"\" Function to create a dictionary out of the cleaned list of words. \n",
        "    We only select words that occur more than 5 times in all of the Data Corpus. \n",
        "    The words are mapped to their indices.     \n",
        "    \"\"\"\n",
        "    counts=dict()\n",
        "    for msgs in messages:\n",
        "\n",
        "        words = fetch_words(msgs)\n",
        "\n",
        "        #remove duplicates\n",
        "        words = list(dict.fromkeys(words))\n",
        "\n",
        "        #count words\n",
        "        for word in words:\n",
        "            counts[word] = counts.get(word,0)+1\n",
        "\n",
        "    my_dict={}\n",
        "    my_list=[]\n",
        "\n",
        "    #consider only keys where count >=5\n",
        "    for key in counts.keys():\n",
        "        if counts[key]>=5:\n",
        "            my_list.append(key)\n",
        "\n",
        "    my_list.sort()    \n",
        "    for i in range (0,len(my_list)):\n",
        "        my_dict[my_list[i]]=i\n",
        "    return my_dict\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ4vIWnHE5XZ"
      },
      "source": [
        "def transform_text(messages, word_dictionary):\n",
        "    \"\"\"Transform a list of messages into a numpy array.\n",
        "\n",
        "    This function creates a numpy array that contains the number of times each word\n",
        "    of the vocabulary appears in each message. \n",
        "    Each row in the resulting array corresponds to each message \n",
        "    and each column corresponds to a word of the vocabulary.\n",
        "    \"\"\"\n",
        "    vocab =  sorted(word_dictionary.keys())\n",
        "    vocab_length = len(word_dictionary.keys())\n",
        "    num_messages = len(messages)\n",
        "\n",
        "    arr = np.zeros((num_messages,vocab_length), dtype=np.float128)\n",
        "    for i in range(0,num_messages):\n",
        "        words=fetch_words(messages[i])\n",
        "          \n",
        "        for word in words:\n",
        "            if word in vocab:\n",
        "                j = vocab.index(word)\n",
        "                arr[i][j]+=1\n",
        "\n",
        "    return arr\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7epnyG6PHXMc"
      },
      "source": [
        "\n",
        "def fit_naive_bayes_model(matrix, labels):\n",
        "    #We then create our model using the Bayesian formula for conditional probability. \n",
        "    \"\"\"Fit a naive bayes model.\n",
        "\n",
        "    This function fits a Naive Bayes model when given a training matrix and labels.\n",
        "    \"\"\"\n",
        "    ph_y1_arr = []\n",
        "    ph_y0_arr = []\n",
        "    ph_y = 0\n",
        "    \n",
        "    # ph_y is overall probability that a message is spam.\n",
        "    num_messages,vocab = matrix.shape\n",
        "    #Split into Spam and non spam matrices\n",
        "    for i in range(0,num_messages):\n",
        "        if labels[i]==1:\n",
        "            ph_y1_arr.append(matrix[i])\n",
        "        else:\n",
        "            ph_y0_arr.append(matrix[i])\n",
        "    \n",
        "    #convert lists to numpy arrays\n",
        "    ph_y1_np = np.array(ph_y1_arr)\n",
        "    ph_y0_np = np.array(ph_y0_arr)\n",
        "\n",
        "    ph_y1 = (1+np.sum(ph_y1_np, axis=0))/(len(ph_y1_np)+vocab)\n",
        "    ph_y0 = (1+np.sum(ph_y0_np, axis=0))/(len(ph_y0_np)+vocab)\n",
        "\n",
        "    ph_y= len(ph_y1_np)/num_messages\n",
        "\n",
        "    return ph_y0, ph_y1, ph_y\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wejx07TbZ0X"
      },
      "source": [
        "def predict_from_naive_bayes_model(model, matrix):\n",
        "    #Use a Naive Bayes model to compute predictions for a target matrix.\n",
        "    ph_y0, ph_y1, ph_y = model\n",
        "\n",
        "    matrix[matrix>1]=1\n",
        "\n",
        "    y1 = ph_y1*matrix\n",
        "    y1[y1==0]=1 \n",
        "    y0 = ph_y0*matrix\n",
        "    y0[y0==0]=1 \n",
        "    \n",
        "    num_messages, vocab = matrix.shape\n",
        "\n",
        "    p1= np.exp(np.sum(np.log(y1), axis=1))*ph_y\n",
        "    \n",
        "\n",
        "    p0= np.exp(np.sum(np.log(y0), axis=1))*(1-ph_y)\n",
        "   \n",
        "    probabilities=[]\n",
        "    for i in range(0,len(p0)):\n",
        "        if p0[i]>=p1[i]:\n",
        "            probabilities.append(0)\n",
        "        else:\n",
        "            probabilities.append(1)\n",
        "    return np.array(probabilities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T3REW-fJ8J2"
      },
      "source": [
        "def fetch_top_five_naive_bayes_words(model, dictionary):\n",
        "    \"\"\" Here we compute the top five words that are most indicative of\n",
        "    the spam (i.e positive) class.\n",
        "    \"\"\"\n",
        "\n",
        "    reversed_dictionary = {v : k for (k, v) in dictionary.items()}\n",
        "    \n",
        "    phi_y0,phi_y1,phi_y = model\n",
        "\n",
        "    logs = np.log(phi_y1)-np.log(phi_y0) \n",
        "    sorted_args = np.argsort(logs)\n",
        "    top_5 = sorted_args[-5:]    \n",
        "    ret = [reversed_dictionary[i] for i in top_5]\n",
        "\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLFDSDTKKWru"
      },
      "source": [
        "def load_spam_dataset(tsv_path):\n",
        "    messages = []\n",
        "    labels = []\n",
        "\n",
        "    with open(tsv_path, 'r', newline='', encoding='utf8') as tsv_file:\n",
        "        reader = csv.reader(tsv_file, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "\n",
        "        for label, message in reader:\n",
        "            messages.append(message)\n",
        "            labels.append(1 if label == 'spam' else 0)\n",
        "\n",
        "    return messages, np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "besiMDgYKnP4",
        "outputId": "35023dab-33d7-4acf-b631-1394767cafa7"
      },
      "source": [
        "def main():\n",
        "    train_messages, train_labels = load_spam_dataset('spam_train.tsv')\n",
        "    val_messages, val_labels = load_spam_dataset('spam_val.tsv')\n",
        "    test_messages, test_labels = load_spam_dataset('spam_test.tsv')\n",
        "\n",
        "    dictionary = create_dictionary(train_messages)\n",
        "\n",
        "    print('Size of dictionary: ', len(dictionary))\n",
        "\n",
        "  \n",
        "    train_matrix = transform_text(train_messages, dictionary)\n",
        "\n",
        "    \n",
        "    val_matrix = transform_text(val_messages, dictionary)\n",
        "    test_matrix = transform_text(test_messages, dictionary)\n",
        "\n",
        "    naive_bayes_model = fit_naive_bayes_model(train_matrix, train_labels)\n",
        "\n",
        "    naive_bayes_predictions_v = predict_from_naive_bayes_model(naive_bayes_model, val_matrix)\n",
        "\n",
        "\n",
        "    naive_bayes_accuracy_v = np.mean(naive_bayes_predictions_v == val_labels)\n",
        "\n",
        "    print('\\nNaive Bayes had an accuracy of {} on the validation set'.format(naive_bayes_accuracy_v))\n",
        "\n",
        "    naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, test_matrix)\n",
        "\n",
        "    naive_bayes_accuracy = np.mean(naive_bayes_predictions == test_labels)\n",
        "\n",
        "    print('\\nNaive Bayes had an accuracy of {} on the testing set'.format(naive_bayes_accuracy))\n",
        "\n",
        "    top_5_words = fetch_top_five_naive_bayes_words(naive_bayes_model, dictionary)\n",
        "\n",
        "    print('\\nThe top 5 indicative words for Naive Bayes are: ', top_5_words)\n",
        "\n",
        "\n",
        "    msg_matrix = transform_text(Messages, dictionary)\n",
        "    spam_or_ham = predict_from_naive_bayes_model(naive_bayes_model, msg_matrix)\n",
        "\n",
        "    for i in range(len(Messages)):\n",
        "      if spam_or_ham[i]==1:\n",
        "        print(\"\\nThe message \\\"{}\\\" is:\\nSPAM!\".format(Messages[i]))\n",
        "      else: \n",
        "        print(\"\\nThe message \\\"{}\\\" is:\\nNOT SPAM!\".format(Messages[i]))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of dictionary:  1498\n",
            "\n",
            "Naive Bayes had an accuracy of 0.9820466786355476 on the validation set\n",
            "\n",
            "Naive Bayes had an accuracy of 0.9874551971326165 on the testing set\n",
            "\n",
            "The top 5 indicative words for Naive Bayes are:  ['guaranteed', 'tone', 'won', 'prize', 'claim']\n",
            "\n",
            "The message \"Please enter your bank account number here \" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Winner claim secret prize now\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"You’ve Won!\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \" How was your day\" is:\n",
            "NOT SPAM!\n",
            "\n",
            "The message \"Amazon Gift card worth Rs 500!!! \" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Winner claim secret prize now\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Hurry !Claim your prize of Rs 50000 now\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Good luck with School\" is:\n",
            "NOT SPAM!\n",
            "\n",
            "The message \"Buy our new product to give you guaranteed results\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Let's go shopping tomorrow!\" is:\n",
            "NOT SPAM!\n",
            "\n",
            "The message \"send credit card info \" is:\n",
            "SPAM!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AswpVSWVYcZY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}